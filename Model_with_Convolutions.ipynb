{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 200) \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Preparation for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"D:\\Machine Learning\\Analytics Vidhya\\\\train_E6oV3lV.csv\")\n",
    "test = pd.read_csv(\"D:\\Machine Learning\\Analytics Vidhya\\\\test_tweets_anuFYb8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in urð±!!! ðððð",
       "ð¦ð¦ð¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0   1      0   \n",
       "1   2      0   \n",
       "2   3      0   \n",
       "3   4      0   \n",
       "4   5      0   \n",
       "\n",
       "                                                                                                                        tweet  \n",
       "0                       @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run  \n",
       "1  @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked  \n",
       "2                                                                                                         bihday your majesty  \n",
       "3                                      #model   i love u take with u all the time in urð±!!! ðððð\n",
       "ð¦ð¦ð¦    \n",
       "4                                                                                      factsguide: society now    #motivation  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49159, 3)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combi = train.append(test,ignore_index = True)\n",
    "combi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt,pattern):\n",
    "    \n",
    "    r = re.findall(pattern,input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i,'',input_txt)\n",
    "    \n",
    "    return input_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "combi['tidy_tweet'] = np.vectorize(remove_pattern)(combi['tweet'],\"@[\\w]*\")\n",
    "combi['tidy_tweet'] = combi['tidy_tweet'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "combi['tidy_tweet'] = combi['tidy_tweet'].apply(lambda x: \" \".join([w for w in x.split() if len(w)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = combi['tidy_tweet'].values\n",
    "tweets_len = [len(t.split()) for t in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(tweets_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "      <td>when father dysfunctional selfish drags kids into dysfunction #run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "      <td>thanks #lyft credit cause they offer wheelchair vans #disapointed #getthanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in urð±!!! ðððð",
       "ð¦ð¦ð¦</td>\n",
       "      <td>#model love take with time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0   1    0.0   \n",
       "1   2    0.0   \n",
       "2   3    0.0   \n",
       "3   4    0.0   \n",
       "4   5    0.0   \n",
       "\n",
       "                                                                                                                        tweet  \\\n",
       "0                       @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run   \n",
       "1  @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked   \n",
       "2                                                                                                         bihday your majesty   \n",
       "3                                      #model   i love u take with u all the time in urð±!!! ðððð\n",
       "ð¦ð¦ð¦     \n",
       "4                                                                                      factsguide: society now    #motivation   \n",
       "\n",
       "                                                                      tidy_tweet  \n",
       "0             when father dysfunctional selfish drags kids into dysfunction #run  \n",
       "1  thanks #lyft credit cause they offer wheelchair vans #disapointed #getthanked  \n",
       "2                                                            bihday your majesty  \n",
       "3                                                     #model love take with time  \n",
       "4                                                 factsguide society #motivation  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "combi_train = combi.iloc[:31962,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 400000\n",
    "max_text_length = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(combi_train.tidy_tweet.values, \n",
    "                                                  combi_train.label.values, \n",
    "                                                  test_size=0.15, \n",
    "                                                  random_state=17, \n",
    "                                                  stratify=combi_train.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tokenizer = text.Tokenizer(max_features)  # will convert into corresponding index and will discard the rest(only 1st 20000)\n",
    "x_tokenizer.fit_on_texts(list(combi_train.tidy_tweet.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tokenized = x_tokenizer.texts_to_sequences(X_train)\n",
    "x_train = sequence.pad_sequences(x_train_tokenized,maxlen = max_text_length)\n",
    "\n",
    "x_val_tokenized = x_tokenizer.texts_to_sequences(X_val)\n",
    "x_val = sequence.pad_sequences(x_val_tokenized,maxlen = max_text_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "embeddings_index ={}\n",
    "f = open('C:\\\\Users\\\\Sayan6619\\\\Twitter Sentiment Analysis\\\\TEXT CLASSI WITH CONVO\\\\glove.6B.100d.txt',encoding=\"utf8\")\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:],dtype = 'float32')\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "f.close()\n",
    "\n",
    "print(f'Found {len(embeddings_index)} word vectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((max_features,embedding_dim))\n",
    "\n",
    "for word,index in x_tokenizer.word_index.items():\n",
    "    if index>max_features-1:\n",
    "        break\n",
    "    else:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features,\n",
    "                   embedding_dim,\n",
    "                   embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "                   trainable=False))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, None, 100)         40000000  \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, None, 250)         75250     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, None, 250)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, None, 250)         312750    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_13 (Glo (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 40,451,001\n",
      "Trainable params: 451,001\n",
      "Non-trainable params: 40,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Conv1D(filters,\n",
    "         kernel_size,\n",
    "         padding='valid'))\n",
    "\n",
    "model.add(MaxPooling1D())\n",
    "\n",
    "model.add(Conv1D(filters,\n",
    "                5,\n",
    "                padding='valid',\n",
    "                activation='relu'))\n",
    "\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(hidden_dims,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.metrics.Precision(),tf.keras.metrics.Recall()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=[tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train,x_val,y_train,y_val = train_test_split(x_train_val,y,test_size=0.15,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27167 samples, validate on 4795 samples\n",
      "Epoch 1/10\n",
      "27167/27167 [==============================] - 28s 1ms/sample - loss: 0.1880 - precision_10: 0.6489 - recall_10: 0.2618 - val_loss: 0.1496 - val_precision_10: 0.8205 - val_recall_10: 0.2857\n",
      "Epoch 2/10\n",
      "27167/27167 [==============================] - 24s 896us/sample - loss: 0.1548 - precision_10: 0.7288 - recall_10: 0.3736 - val_loss: 0.1446 - val_precision_10: 0.7785 - val_recall_10: 0.3661\n",
      "Epoch 3/10\n",
      "27167/27167 [==============================] - 25s 934us/sample - loss: 0.1361 - precision_10: 0.7754 - recall_10: 0.4764 - val_loss: 0.1397 - val_precision_10: 0.8246 - val_recall_10: 0.4196\n",
      "Epoch 4/10\n",
      "27167/27167 [==============================] - 24s 872us/sample - loss: 0.1188 - precision_10: 0.8022 - recall_10: 0.5404 - val_loss: 0.1525 - val_precision_10: 0.7939 - val_recall_10: 0.3899\n",
      "Epoch 5/10\n",
      "27167/27167 [==============================] - 24s 867us/sample - loss: 0.1012 - precision_10: 0.8442 - recall_10: 0.6196 - val_loss: 0.1585 - val_precision_10: 0.7788 - val_recall_10: 0.4821\n",
      "Epoch 6/10\n",
      "27167/27167 [==============================] - 24s 867us/sample - loss: 0.0875 - precision_10: 0.8577 - recall_10: 0.6768 - val_loss: 0.1664 - val_precision_10: 0.6179 - val_recall_10: 0.6161\n",
      "Epoch 7/10\n",
      "27167/27167 [==============================] - 24s 884us/sample - loss: 0.0751 - precision_10: 0.8765 - recall_10: 0.7225 - val_loss: 0.1948 - val_precision_10: 0.7970 - val_recall_10: 0.4792\n",
      "Epoch 8/10\n",
      "27167/27167 [==============================] - 11s 396us/sample - loss: 0.0619 - precision_10: 0.9049 - recall_10: 0.7791 - val_loss: 0.2025 - val_precision_10: 0.7600 - val_recall_10: 0.5089\n",
      "Epoch 9/10\n",
      "27167/27167 [==============================] - 11s 388us/sample - loss: 0.0575 - precision_10: 0.8996 - recall_10: 0.8090 - val_loss: 0.2167 - val_precision_10: 0.7588 - val_recall_10: 0.5149\n",
      "Epoch 10/10\n",
      "27167/27167 [==============================] - 10s 375us/sample - loss: 0.0501 - precision_10: 0.9119 - recall_10: 0.8305 - val_loss: 0.2006 - val_precision_10: 0.6135 - val_recall_10: 0.5952\n",
      "Wall time: 3min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c8dfbcdb08>"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# batch_size=32\n",
    "epoch=10\n",
    "\n",
    "model.fit(x_train,y_train,\n",
    "#          batch_size=batch_size,\n",
    "         epochs=epoch,\n",
    "         validation_data = (x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8692986111111112"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2*0.9119*0.8305)/(0.9119+0.8305)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = combi['tidy_tweet'][31962:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_tokenized = x_tokenizer.texts_to_sequences(x_test)\n",
    "x_testing = sequence.pad_sequences(x_test_tokenized,maxlen = max_text_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17197/17197 [==============================] - 2s 101us/sample\n"
     ]
    }
   ],
   "source": [
    "y_testing = model.predict(x_testing,verbose = 1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17197, 1)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_testing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00313842], dtype=float32)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_testing[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'] = ['non_racist' if x<.5 else 'racist' for x in y_testing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to see the new â  #birdsâ #movie â and hereâs why</td>\n",
       "      <td>racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>31973</td>\n",
       "      <td>1000dayswasted - narcosis infinite ep.. make me aware.. grinding neuro bass #lifestyle</td>\n",
       "      <td>racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>31982</td>\n",
       "      <td>thought factory: bbc neutrality on right wing fascism  #politics #media #blm #brexit #trump #leadership &amp;gt;3</td>\n",
       "      <td>racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>31989</td>\n",
       "      <td>chick gets fucked hottest naked lady</td>\n",
       "      <td>racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>31996</td>\n",
       "      <td>suppo the #taiji fisherman! no bullying! no racism! #tweet4taiji #thecove #seashepherd</td>\n",
       "      <td>racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17161</th>\n",
       "      <td>49124</td>\n",
       "      <td>@user fuck yes!! @user mr money in the bank ðð so dam proud!! @user #mitb #ambroseasylum</td>\n",
       "      <td>racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17176</th>\n",
       "      <td>49139</td>\n",
       "      <td>@user @user are the most racist pay ever!!!!!</td>\n",
       "      <td>racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17188</th>\n",
       "      <td>49151</td>\n",
       "      <td>black professor demonizes, proposes nazi style confiscation of \"white\" assets; like 1930's germany  #breaking</td>\n",
       "      <td>racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17192</th>\n",
       "      <td>49155</td>\n",
       "      <td>thought factory: left-right polarisation! #trump #uselections2016 #leadership #politics  #brexit #blm &amp;gt;3</td>\n",
       "      <td>racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17194</th>\n",
       "      <td>49157</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;amp; used words like \"assets&amp;amp;liability\" never once did #clinton say thee(word) #radicalization</td>\n",
       "      <td>racist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1062 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  \\\n",
       "1      31964   \n",
       "10     31973   \n",
       "19     31982   \n",
       "26     31989   \n",
       "33     31996   \n",
       "...      ...   \n",
       "17161  49124   \n",
       "17176  49139   \n",
       "17188  49151   \n",
       "17192  49155   \n",
       "17194  49157   \n",
       "\n",
       "                                                                                                                                                   tweet  \\\n",
       "1                                                   @user #white #supremacists want everyone to see the new â  #birdsâ #movie â and hereâs why     \n",
       "10                                                             1000dayswasted - narcosis infinite ep.. make me aware.. grinding neuro bass #lifestyle      \n",
       "19                                        thought factory: bbc neutrality on right wing fascism  #politics #media #blm #brexit #trump #leadership &gt;3    \n",
       "26                                                                                                                 chick gets fucked hottest naked lady    \n",
       "33                                                               suppo the #taiji fisherman! no bullying! no racism! #tweet4taiji #thecove #seashepherd    \n",
       "...                                                                                                                                                  ...   \n",
       "17161                                                  @user fuck yes!! @user mr money in the bank ðð so dam proud!! @user #mitb #ambroseasylum      \n",
       "17176                                                                                                     @user @user are the most racist pay ever!!!!!    \n",
       "17188                                     black professor demonizes, proposes nazi style confiscation of \"white\" assets; like 1930's germany  #breaking    \n",
       "17192                                       thought factory: left-right polarisation! #trump #uselections2016 #leadership #politics  #brexit #blm &gt;3    \n",
       "17194  #hillary #campaigned today in #ohio((omg)) &amp; used words like \"assets&amp;liability\" never once did #clinton say thee(word) #radicalization      \n",
       "\n",
       "        label  \n",
       "1      racist  \n",
       "10     racist  \n",
       "19     racist  \n",
       "26     racist  \n",
       "33     racist  \n",
       "...       ...  \n",
       "17161  racist  \n",
       "17176  racist  \n",
       "17188  racist  \n",
       "17192  racist  \n",
       "17194  racist  \n",
       "\n",
       "[1062 rows x 3 columns]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.loc[test['label']=='racist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16135"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.loc[test['label']=='non_racist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1062"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.loc[test['label']=='racist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('Conv1d_text_classifier.h5',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Conv1d_text_classifier\\assets\n"
     ]
    }
   ],
   "source": [
    " tf.keras.models.save_model(model,'Conv1d_text_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.models.load_model('Conv1d_text_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
